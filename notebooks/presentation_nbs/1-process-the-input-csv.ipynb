{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Process the raw input CSV file. \n",
    "\n",
    "# The input for this project is a .csv downloaded from WildTrax. \n",
    "The csv file contains some necessary information to build the training dataset:\n",
    "- start and end times of bird calls\n",
    "- locations of ARUs used to collect the audio\n",
    "- URL link to the recording on which the tags were made. \n",
    "- The date, file type and other metadata associated with the audio.\n",
    "\n",
    "The csv file needs obtaining from WildTrax and placing in the folder named `data/raw/`\n",
    "\n",
    "There is a list of URLs which needs appending to the end of the dataframe. This should contain URL links to the source audio, and the column should be named __recording_url__\n",
    "\n",
    "The lattitude and longitude columns should be present too. \n",
    "\n",
    "The .csv file needs cleaning by running it through the python script __process_raw_csv.py__ \n",
    "\n",
    "This can be done by running this notebook or by running the python file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this notebook is running in a jupyter notebook server, hit __ctrl+enter__ to execute cells in order from top to bottom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Set the paths\n",
    "BASE_PATH = Path.cwd().parent.parent\n",
    "data_path = Path.cwd().parent.parent/'data'\n",
    "sys.path.append(str(BASE_PATH))\n",
    "sys.path.append(str(BASE_PATH / \"src\"))\n",
    "sys.path.append(str(BASE_PATH / \"src\" / \"data\")) \n",
    "\n",
    "from src.data.clean_csv import process_raw_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(data_path/ 'raw' / 'TrainingData_BU&Public_CWS_with_rec_links.csv', low_memory=False)\n",
    "raw_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid mixed data types in the dataframe, a type dictionary is provided. If in the future some columns are added or removed, this type dictionary can be updated to reflect the data type expected. The type dictioary can be found in `src/data/preset_types.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the csv\n",
    "`process_raw_csv` does the following:\n",
    "- Load raw csv file\n",
    "- Drop last entry since it's all NaN values.\n",
    "- Replace empty fields with -1 for verifier_id to enable import to pandas dataframe as int type.\n",
    "- Change all the data types in the DataFrame to the types specified in in the preset_types.py\n",
    "- Drop 'too many to tag' abundance tags.\n",
    "- Specify a value for 'no restrictions' tagging method - since it's stored as 'na' by default\n",
    "- Drop non song vocalizations\n",
    "- Drop recordings not labeled in wildtrax\n",
    "- Remove the clips which don't contain a link to a clip\n",
    "- Remove any clips which belong to a recording with a missing recording_url\n",
    "- Remove clips from projects which might contain data which contaminates the dataset with duplicated or synthetic recordings.\n",
    "- Remove duplicated clips from the database\n",
    "- Add a column to store file type derived from clip URL\n",
    "- Export the cleaned version of the database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing raw csv file...\n",
      "Done processing raw csv file. Outputted to data/interim/cleaned_metadata.pkl\n"
     ]
    }
   ],
   "source": [
    "process_raw_csv(data_path / 'raw' / 'TrainingData_BU&Public_CWS_with_rec_links.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check that it worked\n",
    "Load the processed csv and take a look at the first few lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>organization</th>\n",
       "      <th>project</th>\n",
       "      <th>project_id</th>\n",
       "      <th>location</th>\n",
       "      <th>location_id</th>\n",
       "      <th>recording_date_time</th>\n",
       "      <th>recording_id</th>\n",
       "      <th>task_method</th>\n",
       "      <th>task_id</th>\n",
       "      <th>aru_task_status</th>\n",
       "      <th>...</th>\n",
       "      <th>spectrogram_url</th>\n",
       "      <th>clip_url</th>\n",
       "      <th>sensorId</th>\n",
       "      <th>tasks</th>\n",
       "      <th>status</th>\n",
       "      <th>recording_url</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location_buffer_m</th>\n",
       "      <th>file_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>BU</td>\n",
       "      <td>Alberta Archetypes</td>\n",
       "      <td>1501</td>\n",
       "      <td>P-E0-1-10</td>\n",
       "      <td>308678</td>\n",
       "      <td>2022-06-05 06:51:00</td>\n",
       "      <td>416962</td>\n",
       "      <td>no_restrictions</td>\n",
       "      <td>596169</td>\n",
       "      <td>Transcribed</td>\n",
       "      <td>...</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>ARU</td>\n",
       "      <td>357</td>\n",
       "      <td>Active</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>52.644040</td>\n",
       "      <td>-115.140510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>BU</td>\n",
       "      <td>Amplitude Quality Testing 2020</td>\n",
       "      <td>293</td>\n",
       "      <td>AM-403-SE2</td>\n",
       "      <td>36043</td>\n",
       "      <td>2017-06-15 04:46:00</td>\n",
       "      <td>92051</td>\n",
       "      <td>no_restrictions</td>\n",
       "      <td>87956</td>\n",
       "      <td>Transcribed</td>\n",
       "      <td>...</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>ARU</td>\n",
       "      <td>174</td>\n",
       "      <td>Published - Private</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>54.607774</td>\n",
       "      <td>-110.681271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>BU</td>\n",
       "      <td>Amplitude Quality Testing 2020</td>\n",
       "      <td>293</td>\n",
       "      <td>AM-403-SE2</td>\n",
       "      <td>36043</td>\n",
       "      <td>2017-06-15 04:46:00</td>\n",
       "      <td>92051</td>\n",
       "      <td>no_restrictions</td>\n",
       "      <td>87898</td>\n",
       "      <td>Transcribed</td>\n",
       "      <td>...</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>ARU</td>\n",
       "      <td>174</td>\n",
       "      <td>Published - Private</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>54.607774</td>\n",
       "      <td>-110.681271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>BU</td>\n",
       "      <td>Amplitude Quality Testing 2020</td>\n",
       "      <td>293</td>\n",
       "      <td>AM-403-SE2</td>\n",
       "      <td>36043</td>\n",
       "      <td>2017-06-15 04:46:00</td>\n",
       "      <td>92051</td>\n",
       "      <td>no_restrictions</td>\n",
       "      <td>87840</td>\n",
       "      <td>Transcribed</td>\n",
       "      <td>...</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>ARU</td>\n",
       "      <td>174</td>\n",
       "      <td>Published - Private</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>54.607774</td>\n",
       "      <td>-110.681271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>BU</td>\n",
       "      <td>Amplitude Quality Testing 2020</td>\n",
       "      <td>293</td>\n",
       "      <td>AM-403-SE2</td>\n",
       "      <td>36043</td>\n",
       "      <td>2017-06-15 04:46:00</td>\n",
       "      <td>92051</td>\n",
       "      <td>no_restrictions</td>\n",
       "      <td>87927</td>\n",
       "      <td>Transcribed</td>\n",
       "      <td>...</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>ARU</td>\n",
       "      <td>174</td>\n",
       "      <td>Published - Private</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>54.607774</td>\n",
       "      <td>-110.681271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     organization                         project  project_id    location  \\\n",
       "1623           BU              Alberta Archetypes        1501   P-E0-1-10   \n",
       "1752           BU  Amplitude Quality Testing 2020         293  AM-403-SE2   \n",
       "1758           BU  Amplitude Quality Testing 2020         293  AM-403-SE2   \n",
       "1761           BU  Amplitude Quality Testing 2020         293  AM-403-SE2   \n",
       "1764           BU  Amplitude Quality Testing 2020         293  AM-403-SE2   \n",
       "\n",
       "      location_id  recording_date_time  recording_id      task_method  \\\n",
       "1623       308678  2022-06-05 06:51:00        416962  no_restrictions   \n",
       "1752        36043  2017-06-15 04:46:00         92051  no_restrictions   \n",
       "1758        36043  2017-06-15 04:46:00         92051  no_restrictions   \n",
       "1761        36043  2017-06-15 04:46:00         92051  no_restrictions   \n",
       "1764        36043  2017-06-15 04:46:00         92051  no_restrictions   \n",
       "\n",
       "      task_id aru_task_status  ...  \\\n",
       "1623   596169     Transcribed  ...   \n",
       "1752    87956     Transcribed  ...   \n",
       "1758    87898     Transcribed  ...   \n",
       "1761    87840     Transcribed  ...   \n",
       "1764    87927     Transcribed  ...   \n",
       "\n",
       "                                        spectrogram_url  \\\n",
       "1623  https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "1752  https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "1758  https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "1761  https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "1764  https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "\n",
       "                                               clip_url sensorId tasks  \\\n",
       "1623  https://wildtrax-aru.s3.us-west-2.amazonaws.co...      ARU   357   \n",
       "1752  https://wildtrax-aru.s3.us-west-2.amazonaws.co...      ARU   174   \n",
       "1758  https://wildtrax-aru.s3.us-west-2.amazonaws.co...      ARU   174   \n",
       "1761  https://wildtrax-aru.s3.us-west-2.amazonaws.co...      ARU   174   \n",
       "1764  https://wildtrax-aru.s3.us-west-2.amazonaws.co...      ARU   174   \n",
       "\n",
       "                   status                                      recording_url  \\\n",
       "1623               Active  https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "1752  Published - Private  https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "1758  Published - Private  https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "1761  Published - Private  https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "1764  Published - Private  https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "\n",
       "       latitude   longitude location_buffer_m  file_type  \n",
       "1623  52.644040 -115.140510               NaN       flac  \n",
       "1752  54.607774 -110.681271               NaN       flac  \n",
       "1758  54.607774 -110.681271               NaN       flac  \n",
       "1761  54.607774 -110.681271               NaN       flac  \n",
       "1764  54.607774 -110.681271               NaN       flac  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_csv = pd.read_pickle(data_path / 'interim' / 'cleaned_metadata.pkl')\n",
    "processed_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
