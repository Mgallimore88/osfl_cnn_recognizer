{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate labels for the data from a cleaned csv file.\n",
    "\n",
    "We need to get from the CSV file which is indexed by individual bird vocalization times, to a dataframe which is indexed by 3 second audio clips with a present / absent label. \n",
    "\n",
    "In this notebook we will:\n",
    "- Download recordings containing audio to train the model\n",
    "- Make a dataframe indexed by overlapping 3 second chunks of audio. The windows overlap by 50% and the window length is chosen so that the target species vocalization fits entirely within the window with some spare.\n",
    "- generate target present and absent tags for each window by looking at the window's overlap with human labelled clip start and end times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "BASE_PATH = Path.cwd().parent.parent\n",
    "data_path = BASE_PATH / \"data\" \n",
    "sys.path.append(str(BASE_PATH / \"src\"))\n",
    "sys.path.append(str(BASE_PATH / \"src\" / \"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikeg/miniforge3/envs/osfl2/lib/python3.10/site-packages/opensoundscape/ml/cnn.py:18: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the processed data - this is a cleaned version of the WildTrax csv data with an additional column for recording_url, latitude and longitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>organization</th>\n",
       "      <th>project</th>\n",
       "      <th>project_id</th>\n",
       "      <th>location</th>\n",
       "      <th>location_id</th>\n",
       "      <th>recording_date_time</th>\n",
       "      <th>recording_id</th>\n",
       "      <th>task_method</th>\n",
       "      <th>task_id</th>\n",
       "      <th>aru_task_status</th>\n",
       "      <th>...</th>\n",
       "      <th>spectrogram_url</th>\n",
       "      <th>clip_url</th>\n",
       "      <th>sensorId</th>\n",
       "      <th>tasks</th>\n",
       "      <th>status</th>\n",
       "      <th>recording_url</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location_buffer_m</th>\n",
       "      <th>file_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>BU</td>\n",
       "      <td>Alberta Archetypes</td>\n",
       "      <td>1501</td>\n",
       "      <td>P-E0-1-10</td>\n",
       "      <td>308678</td>\n",
       "      <td>2022-06-05 06:51:00</td>\n",
       "      <td>416962</td>\n",
       "      <td>no_restrictions</td>\n",
       "      <td>596169</td>\n",
       "      <td>Transcribed</td>\n",
       "      <td>...</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>ARU</td>\n",
       "      <td>357</td>\n",
       "      <td>Active</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>52.644040</td>\n",
       "      <td>-115.140510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>BU</td>\n",
       "      <td>Amplitude Quality Testing 2020</td>\n",
       "      <td>293</td>\n",
       "      <td>AM-403-SE2</td>\n",
       "      <td>36043</td>\n",
       "      <td>2017-06-15 04:46:00</td>\n",
       "      <td>92051</td>\n",
       "      <td>no_restrictions</td>\n",
       "      <td>87956</td>\n",
       "      <td>Transcribed</td>\n",
       "      <td>...</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>ARU</td>\n",
       "      <td>174</td>\n",
       "      <td>Published - Private</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>54.607774</td>\n",
       "      <td>-110.681271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>BU</td>\n",
       "      <td>Amplitude Quality Testing 2020</td>\n",
       "      <td>293</td>\n",
       "      <td>AM-403-SE2</td>\n",
       "      <td>36043</td>\n",
       "      <td>2017-06-15 04:46:00</td>\n",
       "      <td>92051</td>\n",
       "      <td>no_restrictions</td>\n",
       "      <td>87898</td>\n",
       "      <td>Transcribed</td>\n",
       "      <td>...</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>ARU</td>\n",
       "      <td>174</td>\n",
       "      <td>Published - Private</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>54.607774</td>\n",
       "      <td>-110.681271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>BU</td>\n",
       "      <td>Amplitude Quality Testing 2020</td>\n",
       "      <td>293</td>\n",
       "      <td>AM-403-SE2</td>\n",
       "      <td>36043</td>\n",
       "      <td>2017-06-15 04:46:00</td>\n",
       "      <td>92051</td>\n",
       "      <td>no_restrictions</td>\n",
       "      <td>87840</td>\n",
       "      <td>Transcribed</td>\n",
       "      <td>...</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>ARU</td>\n",
       "      <td>174</td>\n",
       "      <td>Published - Private</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>54.607774</td>\n",
       "      <td>-110.681271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>BU</td>\n",
       "      <td>Amplitude Quality Testing 2020</td>\n",
       "      <td>293</td>\n",
       "      <td>AM-403-SE2</td>\n",
       "      <td>36043</td>\n",
       "      <td>2017-06-15 04:46:00</td>\n",
       "      <td>92051</td>\n",
       "      <td>no_restrictions</td>\n",
       "      <td>87927</td>\n",
       "      <td>Transcribed</td>\n",
       "      <td>...</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>ARU</td>\n",
       "      <td>174</td>\n",
       "      <td>Published - Private</td>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>54.607774</td>\n",
       "      <td>-110.681271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     organization                         project  project_id    location  \\\n",
       "1623           BU              Alberta Archetypes        1501   P-E0-1-10   \n",
       "1752           BU  Amplitude Quality Testing 2020         293  AM-403-SE2   \n",
       "1758           BU  Amplitude Quality Testing 2020         293  AM-403-SE2   \n",
       "1761           BU  Amplitude Quality Testing 2020         293  AM-403-SE2   \n",
       "1764           BU  Amplitude Quality Testing 2020         293  AM-403-SE2   \n",
       "\n",
       "      location_id  recording_date_time  recording_id      task_method  \\\n",
       "1623       308678  2022-06-05 06:51:00        416962  no_restrictions   \n",
       "1752        36043  2017-06-15 04:46:00         92051  no_restrictions   \n",
       "1758        36043  2017-06-15 04:46:00         92051  no_restrictions   \n",
       "1761        36043  2017-06-15 04:46:00         92051  no_restrictions   \n",
       "1764        36043  2017-06-15 04:46:00         92051  no_restrictions   \n",
       "\n",
       "      task_id aru_task_status  ...  \\\n",
       "1623   596169     Transcribed  ...   \n",
       "1752    87956     Transcribed  ...   \n",
       "1758    87898     Transcribed  ...   \n",
       "1761    87840     Transcribed  ...   \n",
       "1764    87927     Transcribed  ...   \n",
       "\n",
       "                                        spectrogram_url  \\\n",
       "1623  https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "1752  https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "1758  https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "1761  https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "1764  https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "\n",
       "                                               clip_url sensorId tasks  \\\n",
       "1623  https://wildtrax-aru.s3.us-west-2.amazonaws.co...      ARU   357   \n",
       "1752  https://wildtrax-aru.s3.us-west-2.amazonaws.co...      ARU   174   \n",
       "1758  https://wildtrax-aru.s3.us-west-2.amazonaws.co...      ARU   174   \n",
       "1761  https://wildtrax-aru.s3.us-west-2.amazonaws.co...      ARU   174   \n",
       "1764  https://wildtrax-aru.s3.us-west-2.amazonaws.co...      ARU   174   \n",
       "\n",
       "                   status                                      recording_url  \\\n",
       "1623               Active  https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "1752  Published - Private  https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "1758  Published - Private  https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "1761  Published - Private  https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "1764  Published - Private  https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "\n",
       "       latitude   longitude location_buffer_m  file_type  \n",
       "1623  52.644040 -115.140510               NaN       flac  \n",
       "1752  54.607774 -110.681271               NaN       flac  \n",
       "1758  54.607774 -110.681271               NaN       flac  \n",
       "1761  54.607774 -110.681271               NaN       flac  \n",
       "1764  54.607774 -110.681271               NaN       flac  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = pd.read_pickle(data_path / 'interim' / 'cleaned_metadata.pkl')\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have an existing test set, you'll want to make sure it doesn't end up in the training data - otherwise the model will be tested on audio it has already encountered during training - a form of data leakage which will cause over optimistic performance ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data if you have it. \n",
    "existing_test_set = pd.read_csv(data_path / 'raw' / \"SingleSpecies_all.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/test split\n",
    "### Download audio files and make a train+validation/test split of the database. \n",
    "\n",
    "This will download recordings which contained the target species. There might be far too many of these to download all of them, so aim for 2000-4000 total present clips in the training set.\n",
    "\n",
    "The dataframes created here will only reference audio which has been downloaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485 not downloaded\n",
      "downloading 0 clips\n",
      "skipped 0 previously downloaded files\n",
      "dropped 77 locations from training set\n",
      "\n",
      "--------------------------------------------------\n",
      "train set\n",
      "clips per task method = \n",
      " task_method\n",
      "1SPT               35450\n",
      "1SPM               10828\n",
      "no_restrictions     2660\n",
      "Name: count, dtype: int64\n",
      "total clips = 48938\n",
      "\n",
      "clips generated from each tagging method:\n",
      "                 target_present  target_absent\n",
      "task_method                                   \n",
      "1SPM                     1519.0         9309.0\n",
      "1SPT                     2158.0        33292.0\n",
      "no_restrictions           313.0         2347.0\n",
      "total present clips =  3990\n",
      "total absent clips =  44948\n",
      "total available human labelled tags = 48938\n",
      "\n",
      "--------------------------------------------------\n",
      "valid set\n",
      "clips per task method = \n",
      " task_method\n",
      "1SPT               7655\n",
      "1SPM               2899\n",
      "no_restrictions    1053\n",
      "Name: count, dtype: int64\n",
      "total clips = 11607\n",
      "\n",
      "clips generated from each tagging method:\n",
      "                 target_present  target_absent\n",
      "task_method                                   \n",
      "1SPM                      369.0         2530.0\n",
      "1SPT                      423.0         7232.0\n",
      "no_restrictions           219.0          834.0\n",
      "total present clips =  1011\n",
      "total absent clips =  10596\n",
      "total available human labelled tags = 11607\n"
     ]
    }
   ],
   "source": [
    "train_and_valid_df, test_df = build.new_labelled_df(processed_df, target_species=\"OSFL\", download_n=0, existing_test_set=existing_test_set, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the test split somewhere out of the way\n",
    "Don't look at it until after model training and hyperparameter tuning is complete. This is the data the model will be evaluated on after training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_dir = data_path / 'interim' / 'test_set'\n",
    "if not test_set_dir.exists():\n",
    "    Path.mkdir(test_set_dir)\n",
    "test_df.to_pickle(data_path / 'interim' / 'test_set' / 'test_set.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the training and validation sets in a different folder\n",
    "This is the data the model will be trained and evaluated on during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_valid_set_dir = data_path / 'interim' / 'train_and_valid_set'\n",
    "if not train_and_valid_set_dir.exists():\n",
    "    Path.mkdir(train_and_valid_set_dir)\n",
    "train_and_valid_df.to_pickle(data_path / 'interim' / 'train_and_valid_set' / 'train_and_valid_set.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the train and valid set by location in the same way as the train/test split was made\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the folders\n",
    "train_set_dir = data_path / 'interim' / 'train_set'\n",
    "valid_set_dir = data_path / 'interim' / 'valid_set'\n",
    "if not train_set_dir.exists():\n",
    "    Path.mkdir(train_set_dir)\n",
    "if not valid_set_dir.exists():\n",
    "    Path.mkdir(valid_set_dir)\n",
    "\n",
    "# Split the train and valid set\n",
    "train_df, valid_df = build.make_train_valid_split(train_and_valid_df, seed=42, pct_train=0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Clips in training dataset\n",
      "clips per task method = \n",
      " task_method\n",
      "1SPT               29010\n",
      "1SPM                8755\n",
      "no_restrictions     1915\n",
      "Name: count, dtype: int64\n",
      "total clips = 39680\n",
      "\n",
      "clips generated from each tagging method:\n",
      "                 target_present  target_absent\n",
      "task_method                                   \n",
      "1SPM                     1239.0         7516.0\n",
      "1SPT                     1813.0        27197.0\n",
      "no_restrictions           251.0         1664.0\n",
      "total present clips =  3303\n",
      "total absent clips =  36377\n",
      "total available human labelled tags = 39680\n",
      "\n",
      "--------------------------------------------------\n",
      "Clips in validation dataset\n",
      "clips per task method = \n",
      " task_method\n",
      "1SPT               6440\n",
      "1SPM               2073\n",
      "no_restrictions     745\n",
      "Name: count, dtype: int64\n",
      "total clips = 9258\n",
      "\n",
      "clips generated from each tagging method:\n",
      "                 target_present  target_absent\n",
      "task_method                                   \n",
      "1SPM                      280.0         1793.0\n",
      "1SPT                      345.0         6095.0\n",
      "no_restrictions            62.0          683.0\n",
      "total present clips =  687\n",
      "total absent clips =  8571\n",
      "total available human labelled tags = 9258\n"
     ]
    }
   ],
   "source": [
    "build.report_counts(train_df, header=\"Clips in training dataset\")\n",
    "build.report_counts(valid_df, header=\"Clips in validation dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the train and valid set into different folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the train and valid sets\n",
    "train_df.to_pickle(data_path / 'interim' / 'train_set' / 'train_set.pkl')\n",
    "valid_df.to_pickle(data_path / 'interim' / 'valid_set' / 'valid_set.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
