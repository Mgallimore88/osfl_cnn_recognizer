{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook aims to identify sections of audio containing target vocalization, and sections which do not contain the target vocalization. \n",
    "\n",
    "__proxy for target vocalisation:__ \n",
    "- Audio from a section of a recording contianing target vocalizaition, and taken from within the same timestamp as the tag. \n",
    "- Audio from a recording with tagging method 'no restrictions' AND taken from within tag timestamp of the target species. \n",
    "\n",
    "__proxys for NOT target vocalization__\n",
    "- Audio from a recording with tagging method '1SPM' AND there is no target species tag in the recording\n",
    "- Audio from a recording with tagging method '1SPM' AND there is an target species tag in the recording AND the sample is taken from before the start of the target species tag. \n",
    "- Audio from a recording with tagging method 'no restrictions' AND taken from inbetween tags of the target species. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "BASE_PATH = Path.cwd().parents[1]\n",
    "sys.path.append(str(BASE_PATH / \"src\" / \"data\"))  # for clean_csv and train_test_split\n",
    "sys.path.append(str(BASE_PATH / \"src\"))  # for utils\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(BASE_PATH / \"data\"/\"processed\" / \"train_set\" / \"train_set.pkl\")\n",
    "df_lite = df[keep_cols]\n",
    "osfls = df_lite.loc[df.species_code == 'OSFL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the distribution of the different tagging methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_method\n",
       "1SPT                        201904\n",
       "1SPM                        178249\n",
       "NaN                          50291\n",
       "1SPM Audio/Visual hybrid      2530\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.task_method.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1SPT = 1 sample per task <br> 1SPM = 1 sample per minute\n",
    "- If the tagging method is 1SPT then the time interval is the duration of the recording.\n",
    "- In each case, the audio before the onset of the target species vocalization can be treated as audio which does not contain the target audio. \n",
    "- In the 1SPM recordings, there are additional sources of the negative target, found between the start of each minute, and the onset of the target vocalization within that minute. \n",
    "- Initially the two classes will be treated the same, since audio for the null class isn't scarce. \n",
    "\n",
    "### What about the 'None' method?\n",
    "- The 'None' method, or sections of the dataframe without a string value for the tagging method, are tasks without a restriction on the number of tags. These can be used as a source of positive and negative class recordigs. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many recording files are there in the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54416,) unique recordings, (2967,) recordings with the target species present.\n"
     ]
    }
   ],
   "source": [
    "unique_recordings = df.recording_id.unique()\n",
    "recordings_containing_target_species = osfls.recording_id.unique()\n",
    "print(f\"{unique_recordings.shape} unique recordings, {recordings_containing_target_species.shape} recordings with the target species present.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at how to group df by recording and keep the other info\n",
    "- recording ids and urls are all the same for each tag entry in the database. \n",
    "- It would be useful to have the database indexed by recording ID, and have the species tag, clip start/stop time etc stored as a list per recording. That way we could see the timestamps of all the clips for one recording. \n",
    "\n",
    "- Using an aggregate function, we can pass a dictionary into the groupby function so that different columns are grouped differently. This way we can end up with a list of all the target species start stop times per recording. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_url</th>\n",
       "      <th>detection_time</th>\n",
       "      <th>tag_duration</th>\n",
       "      <th>file_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recording_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4396</th>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>[27.28, 95.9]</td>\n",
       "      <td>[0.83, 1.18]</td>\n",
       "      <td>mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>[32.63, 82.51]</td>\n",
       "      <td>[1.33, 1.11]</td>\n",
       "      <td>mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4427</th>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>[106.56, 122.66]</td>\n",
       "      <td>[1.0, 0.84]</td>\n",
       "      <td>mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4429</th>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>[31.11, 74.7, 139.78]</td>\n",
       "      <td>[1.38, 2.19, 1.29]</td>\n",
       "      <td>mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4446</th>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>[13.63, 74.88, 126.6]</td>\n",
       "      <td>[1.05, 0.89, 0.8]</td>\n",
       "      <td>mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826329</th>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>[15.06]</td>\n",
       "      <td>[0.54]</td>\n",
       "      <td>flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826352</th>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>[6.7]</td>\n",
       "      <td>[0.95]</td>\n",
       "      <td>flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826374</th>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>[4.11, 16.04]</td>\n",
       "      <td>[0.96, 0.88]</td>\n",
       "      <td>flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826375</th>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>[2.16, 48.0]</td>\n",
       "      <td>[0.66, 0.83]</td>\n",
       "      <td>flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829015</th>\n",
       "      <td>https://wildtrax-aru.s3.us-west-2.amazonaws.co...</td>\n",
       "      <td>[12.0]</td>\n",
       "      <td>[0.64]</td>\n",
       "      <td>flac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2967 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  recording_url  \\\n",
       "recording_id                                                      \n",
       "4396          https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "4399          https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "4427          https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "4429          https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "4446          https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "...                                                         ...   \n",
       "826329        https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "826352        https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "826374        https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "826375        https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "829015        https://wildtrax-aru.s3.us-west-2.amazonaws.co...   \n",
       "\n",
       "                     detection_time        tag_duration file_type  \n",
       "recording_id                                                       \n",
       "4396                  [27.28, 95.9]        [0.83, 1.18]       mp3  \n",
       "4399                 [32.63, 82.51]        [1.33, 1.11]       mp3  \n",
       "4427               [106.56, 122.66]         [1.0, 0.84]       mp3  \n",
       "4429          [31.11, 74.7, 139.78]  [1.38, 2.19, 1.29]       mp3  \n",
       "4446          [13.63, 74.88, 126.6]   [1.05, 0.89, 0.8]       mp3  \n",
       "...                             ...                 ...       ...  \n",
       "826329                      [15.06]              [0.54]      flac  \n",
       "826352                        [6.7]              [0.95]      flac  \n",
       "826374                [4.11, 16.04]        [0.96, 0.88]      flac  \n",
       "826375                 [2.16, 48.0]        [0.66, 0.83]      flac  \n",
       "829015                       [12.0]              [0.64]      flac  \n",
       "\n",
       "[2967 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_species = 'OSFL'\n",
    "filtered_df = df.loc[df.species_code == target_species]\n",
    "grouped = filtered_df.groupby('recording_id').agg({'recording_url': 'first', 'detection_time': lambda x: list(x), 'tag_duration': lambda x: list(x), 'file_type': 'first'})\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/mikeg/code/machine_learning/osfl_cnn_recognizer/notebooks/exploratory_nbs/1.12-mjg-get-samples_from_recordings.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mikeg/code/machine_learning/osfl_cnn_recognizer/notebooks/exploratory_nbs/1.12-mjg-get-samples_from_recordings.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m grouped\u001b[39m.\u001b[39mloc[grouped\u001b[39m.\u001b[39mindex \u001b[39m<\u001b[39m \u001b[39m4427\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mikeg/code/machine_learning/osfl_cnn_recognizer/notebooks/exploratory_nbs/1.12-mjg-get-samples_from_recordings.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m grouped[\u001b[39m'\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m grouped\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m) \u001b[39m+\u001b[39m file_type\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file_type' is not defined"
     ]
    }
   ],
   "source": [
    "grouped.loc[grouped.index < 4427]\n",
    "grouped['filename'] = grouped.index.astype(str) + file_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First let's build a dataset by downloading only the recordings which contain the target species\n",
    "### This dataset will also be accompanied by a dataframe with the file path as its index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading 10 clips\n",
      "skipped 10 previously downloaded files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://wildtrax-aru.s3.us-west-2.amazonaws.com/d587fac1-ae78-4729-b816-5e6eaf5a5c9e/255412.mp3'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import download_recordings\n",
    "audio_save_path = Path(BASE_PATH / \"data\" / \"raw\" / \"recordings\" / \"OSFL\")\n",
    "audio_save_path.mkdir(parents=True, exist_ok=True)\n",
    "download_recordings.from_url(df, 'recording_url', audio_save_path, target = 'OSFL', n=10)\n",
    "osfls['recording_url'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opensoundscape "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osfl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
